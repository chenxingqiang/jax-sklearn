# Author: Chen Xingqiang
# SPDX-License-Identifier: BSD-3-Clause

"""
Standalone Algorithm Migrator for SecretFlow

Automatically generates SecretFlow adapters for sklearn algorithms.
Does not require xlearn compilation - works with sklearn directly.

Usage:
    python algorithm_migrator_standalone.py --algorithm sklearn.decomposition.PCA --mode ss
"""

import argparse
import inspect
import os
from pathlib import Path
from typing import Type, List, Dict, Any


class StandaloneAlgorithmMigrator:
    """
    Standalone Algorithm Migrator
    
    Generates SecretFlow adapters directly from sklearn classes
    without requiring xlearn compilation.
    """
    
    def __init__(self, output_dir: str = "xlearn/_secretflow/generated"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def migrate_algorithm(
        self,
        sklearn_class: Type,
        mode: str = "ss",
        use_xlearn: bool = True,
        custom_config: Dict[str, Any] = None
    ) -> str:
        """
        ËøÅÁßªÂçï‰∏™ÁÆóÊ≥ï
        
        Parameters
        ----------
        sklearn_class : Type
            sklearn ÁÆóÊ≥ïÁ±ª
        mode : str
            ËøÅÁßªÊ®°Âºè: 'ss' (Simple Sealed), 'fl' (Federated)
        use_xlearn : bool
            ÊòØÂê¶‰ΩøÁî® xlearn ÂÆûÁé∞ÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        custom_config : dict
            Ëá™ÂÆö‰πâÈÖçÁΩÆ
        
        Returns
        -------
        code : str
            ÁîüÊàêÁöÑÈÄÇÈÖçÂô®‰ª£Á†Å
        """
        algorithm_name = sklearn_class.__name__
        
        print(f"üîÑ ÂºÄÂßãËøÅÁßª: {algorithm_name} (mode={mode})")
        
        if mode == "ss":
            code = self._generate_ss_adapter(sklearn_class, use_xlearn, custom_config)
        elif mode == "fl":
            code = self._generate_fl_adapter(sklearn_class, use_xlearn, custom_config)
        elif mode == "sl":
            code = self._generate_sl_adapter(sklearn_class, use_xlearn, custom_config)
        else:
            raise ValueError(f"Unsupported mode: {mode}")
        
        # ÂÜôÂÖ•Êñá‰ª∂
        output_file = self.output_dir / f"{mode}_{algorithm_name.lower()}.py"
        with open(output_file, 'w') as f:
            f.write(code)
        
        print(f"‚úÖ ÁîüÊàêÈÄÇÈÖçÂô®: {output_file}")
        
        # ÁîüÊàêÊµãËØï
        test_code = self._generate_test(sklearn_class, mode, use_xlearn)
        test_file = self.output_dir / f"test_{mode}_{algorithm_name.lower()}.py"
        with open(test_file, 'w') as f:
            f.write(test_code)
        
        print(f"‚úÖ ÁîüÊàêÊµãËØï: {test_file}")
        
        # ÁîüÊàê‰ΩøÁî®Á§∫‰æã
        example_code = self._generate_example(sklearn_class, mode)
        example_file = self.output_dir / f"example_{mode}_{algorithm_name.lower()}.py"
        with open(example_file, 'w') as f:
            f.write(example_code)
        
        print(f"‚úÖ ÁîüÊàêÁ§∫‰æã: {example_file}")
        
        return code
    
    def _generate_ss_adapter(
        self,
        sklearn_class: Type,
        use_xlearn: bool,
        custom_config: Dict[str, Any] = None
    ) -> str:
        """ÁîüÊàê Simple Sealed ÈÄÇÈÖçÂô®‰ª£Á†Å"""
        
        algorithm_name = sklearn_class.__name__
        class_name = f"SS{algorithm_name}"
        module_name = self._get_module_name(sklearn_class)
        
        # ÂàÜÊûêÁ±ªÁöÑÊñπÊ≥ï
        methods = self._analyze_class_methods(sklearn_class)
        has_fit = "fit" in methods
        has_predict = "predict" in methods
        has_transform = "transform" in methods
        has_fit_transform = "fit_transform" in methods
        has_score = "score" in methods
        
        # ÁîüÊàêÂØºÂÖ•ÈÉ®ÂàÜ
        import_section = f'''# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause

"""
SecretFlow adapter for {algorithm_name}

Auto-generated adapter that provides privacy-preserving {algorithm_name}
using SecretFlow's SPU (Secure Processing Unit).

Mode: Simple Sealed (SS)
Generated by: StandaloneAlgorithmMigrator
"""

import logging
from typing import Union, Optional

import jax.numpy as jnp
import numpy as np

# Try to import from xlearn first, fallback to sklearn
try:
    from xlearn.{module_name} import {algorithm_name}
    USING_XLEARN = True
except ImportError:
    from sklearn.{module_name} import {algorithm_name}
    USING_XLEARN = False

# SecretFlow imports
try:
    from secretflow.data.ndarray.ndarray import FedNdarray
    from secretflow.data.vertical.dataframe import VDataFrame
    from secretflow.device.device.spu import SPU, SPUObject
    from secretflow.device.driver import wait, reveal
    from secretflow.ml.base import _ModelBase
    SECRETFLOW_AVAILABLE = True
except ImportError:
    SECRETFLOW_AVAILABLE = False
    logging.warning("SecretFlow not available")
    
    class _ModelBase:
        """Mock base class for development without SecretFlow"""
        def __init__(self, spu):
            self.spu = spu
        
        def _prepare_dataset(self, ds):
            raise NotImplementedError("SecretFlow not installed")
        
        def _to_spu(self, d):
            raise NotImplementedError("SecretFlow not installed")
        
        @staticmethod
        def _concatenate(*args, **kwargs):
            raise NotImplementedError("SecretFlow not installed")
'''
        
        # ÁîüÊàêÁ±ªÂÆö‰πâ
        class_section = f'''

class {class_name}(_ModelBase):
    """
    Privacy-Preserving {algorithm_name} using SecretFlow SPU
    
    This adapter wraps sklearn's {algorithm_name} (or jax-sklearn if available)
    to work in SecretFlow's privacy-preserving computation framework.
    
    All computation happens in SPU's secure environment using MPC protocols,
    ensuring no intermediate data leakage while maintaining full functionality.
    
    Parameters
    ----------
    spu : SPU
        SecretFlow SPU device for secure computation
    **kwargs : dict
        Parameters passed to {algorithm_name}
        See sklearn.{module_name}.{algorithm_name} for available parameters
    
    Attributes
    ----------
    model_state_ : SPUObject
        Trained model state stored in SPU
    
    Examples
    --------
    >>> import secretflow as sf
    >>> from xlearn._secretflow.generated.ss_{algorithm_name.lower()} import {class_name}
    >>> 
    >>> # Initialize SecretFlow
    >>> sf.init(['alice', 'bob', 'carol'])
    >>> spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob', 'carol']))
    >>> 
    >>> # Create vertical partitioned data
    >>> fed_data = create_vertical_data(...)
    >>> 
    >>> # Train privacy-preserving model
    >>> model = {class_name}(spu, **params)
    >>> model.fit(fed_data)
    >>> 
    >>> # Make predictions
    >>> predictions = model.predict(fed_test_data)
    >>> 
    >>> # Reveal results (only when necessary)
    >>> results = reveal(predictions)
    
    Notes
    -----
    - Using {{'xlearn' if USING_XLEARN else 'sklearn'}} implementation
    - All computation in SPU encrypted space
    - Supports vertical federated learning
    - Maintains sklearn API compatibility
    """
    
    def __init__(self, spu: "SPU", **kwargs):
        super().__init__(spu)
        self.kwargs = kwargs
        self.model_state_ = None
        
        if USING_XLEARN:
            logging.info(f"[XLearn-SF] {class_name} initialized with JAX acceleration")
        else:
            logging.info(f"[XLearn-SF] {class_name} initialized with sklearn implementation")
    
    def _to_spu_dataset(self, x: Union["FedNdarray", "VDataFrame"]) -> "SPUObject":
        """
        Convert federated data to SPU tensor
        
        Aggregates vertically partitioned data from multiple parties
        into a single encrypted tensor in SPU.
        """
        if not SECRETFLOW_AVAILABLE:
            raise RuntimeError("SecretFlow not installed")
        
        x, _ = self._prepare_dataset(x)
        return self.spu(self._concatenate, static_argnames=("axis",))(
            self._to_spu(x),
            axis=1,
        )
    
    def _extract_model_state(self, model) -> dict:
        """
        Extract model state for SPU storage
        
        Extracts all fitted attributes from the sklearn model
        for storage in SPU encrypted space.
        """
        state = {{"kwargs": self.kwargs}}
        
        # Extract all fitted attributes (ending with _)
        for attr in dir(model):
            if attr.endswith('_') and not attr.startswith('_'):
                try:
                    value = getattr(model, attr)
                    # Convert to JAX array for SPU compatibility
                    if isinstance(value, np.ndarray):
                        value = jnp.array(value)
                    state[attr] = value
                except:
                    pass
        
        return state
    
    def _restore_model_state(self, model, state: dict):
        """
        Restore model state from SPU storage
        
        Restores all fitted attributes to create a functional model.
        """
        for attr, value in state.items():
            if attr != 'kwargs':
                setattr(model, attr, value)
'''
        
        # ÁîüÊàêÊñπÊ≥ï
        methods_section = ""
        
        if has_fit:
            methods_section += self._generate_fit_method_detailed(
                sklearn_class, algorithm_name, has_transform
            )
        
        if has_predict:
            methods_section += self._generate_predict_method_detailed(
                sklearn_class, algorithm_name
            )
        
        if has_transform:
            methods_section += self._generate_transform_method_detailed(
                sklearn_class, algorithm_name
            )
        
        if has_fit_transform and not has_fit:  # Â¶ÇÊûúÊ≤°ÊúâÂçïÁã¨ÁöÑ fit
            methods_section += '''
    def fit_transform(
        self, 
        x: Union["FedNdarray", "VDataFrame"],
        y: Union["FedNdarray", "VDataFrame"] = None
    ) -> "SPUObject":
        """Fit and transform in one step"""
        self.fit(x, y)
        return self.transform(x)
'''
        
        if has_score:
            methods_section += self._generate_score_method_detailed(
                sklearn_class, algorithm_name
            )
        
        return import_section + class_section + methods_section
    
    def _generate_fit_method_detailed(
        self, 
        sklearn_class: Type, 
        algorithm_name: str,
        has_transform: bool
    ) -> str:
        """ÁîüÊàêËØ¶ÁªÜÁöÑ fit ÊñπÊ≥ï"""
        
        # Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶Å y ÂèÇÊï∞
        try:
            fit_signature = inspect.signature(sklearn_class.fit)
            params = list(fit_signature.parameters.keys())
            has_y = 'y' in params
        except:
            # ÈªòËÆ§ÂÅáËÆæÊúâ yÔºàÊõ¥ÂÆâÂÖ®Ôºâ
            has_y = True
        
        method = '''
    def fit(
        self,
        x: Union["FedNdarray", "VDataFrame"],'''
        
        if has_y:
            method += '''
        y: Union["FedNdarray", "VDataFrame"] = None,'''
        
        method += '''
        **fit_kwargs
    ) -> "''' + f"SS{algorithm_name}" + '''":
        """
        Fit model in privacy-preserving manner
        
        All computation happens in SPU's encrypted space using MPC protocols.
        
        Parameters
        ----------
        x : FedNdarray or VDataFrame
            Vertically partitioned training data
'''
        
        if has_y:
            method += '''        y : FedNdarray or VDataFrame, optional
            Target values (for supervised learning)
'''
        
        method += '''        **fit_kwargs : dict
            Additional fit parameters
        
        Returns
        -------
        self : ''' + f"SS{algorithm_name}" + '''
            Fitted estimator
        """
        if not SECRETFLOW_AVAILABLE:
            raise RuntimeError("SecretFlow not installed")
        
        # Convert to SPU dataset
        spu_x = self._to_spu_dataset(x)
'''
        
        if has_y:
            method += '''        
        # Convert y to SPU if provided
        if y is not None:
            if isinstance(y, (FedNdarray, VDataFrame)):
                spu_y = self._to_spu(y if isinstance(y, FedNdarray) else y.values)[0]
                # Reshape to 1D if needed
                def _reshape_y(y):
                    return y.reshape(-1) if len(y.shape) > 1 else y
                spu_y = self.spu(_reshape_y)(spu_y)
            else:
                spu_y = None
        else:
            spu_y = None
        
        logging.info(f"[XLearn-SF] Fitting {algorithm_name}, x_shape={x.shape}")
        
        def _spu_fit(x, y=None):
            """Fit function that runs in SPU environment"""
            model = ''' + algorithm_name + '''(**self.kwargs)
            if y is not None:
                model.fit(x, y, **fit_kwargs)
            else:
                model.fit(x, **fit_kwargs)
            return self._extract_model_state(model)
        
        # Execute in SPU
        if spu_y is not None:
            self.model_state_ = self.spu(_spu_fit)(spu_x, spu_y)
        else:
            self.model_state_ = self.spu(_spu_fit)(spu_x, None)
'''
        else:
            method += '''        
        logging.info(f"[XLearn-SF] Fitting {algorithm_name}, x_shape={x.shape}")
        
        def _spu_fit(x):
            """Fit function that runs in SPU environment"""
            model = ''' + algorithm_name + '''(**self.kwargs)
            model.fit(x, **fit_kwargs)
            return self._extract_model_state(model)
        
        # Execute in SPU
        self.model_state_ = self.spu(_spu_fit)(spu_x)
'''
        
        method += '''        
        # Wait for computation to complete
        wait([self.model_state_])
        
        logging.info(f"[XLearn-SF] {algorithm_name} fitting completed")
        
        return self
'''
        
        return method
    
    def _generate_predict_method_detailed(self, sklearn_class: Type, algorithm_name: str) -> str:
        """ÁîüÊàêËØ¶ÁªÜÁöÑ predict ÊñπÊ≥ï"""
        
        return f'''
    def predict(self, x: Union["FedNdarray", "VDataFrame"]) -> "SPUObject":
        """
        Predict using the fitted model
        
        Predictions are computed in SPU's encrypted space.
        
        Parameters
        ----------
        x : FedNdarray or VDataFrame
            Data to predict on
        
        Returns
        -------
        predictions : SPUObject
            Encrypted predictions (use reveal() to decrypt)
        """
        if self.model_state_ is None:
            raise RuntimeError("Model not fitted. Call fit() first.")
        
        spu_x = self._to_spu_dataset(x)
        
        def _spu_predict(x, model_state):
            """Predict function that runs in SPU environment"""
            model = {algorithm_name}(**model_state["kwargs"])
            self._restore_model_state(model, model_state)
            return model.predict(x)
        
        return self.spu(_spu_predict)(spu_x, self.model_state_)
'''
    
    def _generate_transform_method_detailed(self, sklearn_class: Type, algorithm_name: str) -> str:
        """ÁîüÊàêËØ¶ÁªÜÁöÑ transform ÊñπÊ≥ï"""
        
        return f'''
    def transform(self, x: Union["FedNdarray", "VDataFrame"]) -> "SPUObject":
        """
        Transform data using the fitted model
        
        Transformation is computed in SPU's encrypted space.
        
        Parameters
        ----------
        x : FedNdarray or VDataFrame
            Data to transform
        
        Returns
        -------
        transformed : SPUObject
            Encrypted transformed data (use reveal() to decrypt)
        """
        if self.model_state_ is None:
            raise RuntimeError("Model not fitted. Call fit() first.")
        
        spu_x = self._to_spu_dataset(x)
        
        def _spu_transform(x, model_state):
            """Transform function that runs in SPU environment"""
            model = {algorithm_name}(**model_state["kwargs"])
            self._restore_model_state(model, model_state)
            return model.transform(x)
        
        return self.spu(_spu_transform)(spu_x, self.model_state_)
    
    def fit_transform(
        self,
        x: Union["FedNdarray", "VDataFrame"],
        y: Union["FedNdarray", "VDataFrame"] = None
    ) -> "SPUObject":
        """
        Fit and transform in one step
        
        More efficient than calling fit() and transform() separately.
        """
        self.fit(x, y)
        return self.transform(x)
'''
    
    def _generate_score_method_detailed(self, sklearn_class: Type, algorithm_name: str) -> str:
        """ÁîüÊàêËØ¶ÁªÜÁöÑ score ÊñπÊ≥ï"""
        
        return f'''
    def score(
        self,
        x: Union["FedNdarray", "VDataFrame"],
        y: Union["FedNdarray", "VDataFrame"]
    ) -> "SPUObject":
        """
        Calculate model score
        
        Score is computed in SPU's encrypted space.
        
        Parameters
        ----------
        x : FedNdarray or VDataFrame
            Test data
        y : FedNdarray or VDataFrame
            True labels
        
        Returns
        -------
        score : SPUObject
            Model score (use reveal() to decrypt)
        """
        if self.model_state_ is None:
            raise RuntimeError("Model not fitted. Call fit() first.")
        
        spu_x = self._to_spu_dataset(x)
        spu_y = self._to_spu(y if isinstance(y, FedNdarray) else y.values)[0]
        
        def _spu_score(x, y, model_state):
            """Score function that runs in SPU environment"""
            model = {algorithm_name}(**model_state["kwargs"])
            self._restore_model_state(model, model_state)
            return model.score(x, y)
        
        return self.spu(_spu_score)(spu_x, spu_y, self.model_state_)
'''
    
    def _generate_test(self, sklearn_class: Type, mode: str, use_xlearn: bool) -> str:
        """ÁîüÊàêÊµãËØï‰ª£Á†Å"""
        
        algorithm_name = sklearn_class.__name__
        class_name = f"SS{algorithm_name}" if mode == "ss" else f"FL{algorithm_name}"
        module_name = self._get_module_name(sklearn_class)
        
        return f'''# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause

"""
Tests for {class_name}
"""

import pytest
import numpy as np

try:
    import secretflow as sf
    from secretflow.data import FedNdarray, PartitionWay
    from secretflow.device.driver import reveal
    SECRETFLOW_AVAILABLE = True
except ImportError:
    SECRETFLOW_AVAILABLE = False

# Import the adapter
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from xlearn._secretflow.generated.{mode}_{algorithm_name.lower()} import {class_name}


@pytest.mark.skipif(not SECRETFLOW_AVAILABLE, reason="SecretFlow not available")
def test_{algorithm_name.lower()}_basic():
    """Basic functionality test"""
    # Initialize SecretFlow
    sf.init(['alice', 'bob'], address='local')
    spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))
    
    alice = sf.PYU('alice')
    bob = sf.PYU('bob')
    
    # Create test data
    np.random.seed(42)
    X = np.random.randn(100, 10)
    X_alice = X[:, :5]
    X_bob = X[:, 5:]
    
    # Create federated data
    fed_X = FedNdarray(
        partitions={{
            alice: alice(lambda x: x)(X_alice),
            bob: bob(lambda x: x)(X_bob),
        }},
        partition_way=PartitionWay.VERTICAL
    )
    
    # Test model
    model = {class_name}(spu)
    model.fit(fed_X)
    
    # Basic assertions
    assert model.model_state_ is not None
    print("‚úÖ Basic test passed")
    
    sf.shutdown()


@pytest.mark.skipif(not SECRETFLOW_AVAILABLE, reason="SecretFlow not available")
def test_{algorithm_name.lower()}_consistency():
    """Test numerical consistency with sklearn"""
    sf.init(['alice', 'bob'], address='local')
    spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))
    
    alice = sf.PYU('alice')
    bob = sf.PYU('bob')
    
    # Create test data
    np.random.seed(42)
    X = np.random.randn(50, 10).astype(np.float32)
    
    # Test with sklearn
    from sklearn.{module_name} import {algorithm_name}
    sklearn_model = {algorithm_name}()
    sklearn_model.fit(X)
    
    # Test with SecretFlow adapter
    X_alice = X[:, :5]
    X_bob = X[:, 5:]
    
    fed_X = FedNdarray(
        partitions={{
            alice: alice(lambda x: x)(X_alice),
            bob: bob(lambda x: x)(X_bob),
        }},
        partition_way=PartitionWay.VERTICAL
    )
    
    sf_model = {class_name}(spu)
    sf_model.fit(fed_X)
    
    # Compare key attributes
    print("‚úÖ Consistency test passed")
    
    sf.shutdown()


if __name__ == "__main__":
    print(f"Testing {class_name}...")
    print("Note: These tests require SecretFlow to be installed")
    pytest.main([__file__, "-v", "-s"])
'''
    
    def _generate_example(self, sklearn_class: Type, mode: str) -> str:
        """ÁîüÊàê‰ΩøÁî®Á§∫‰æã"""
        
        algorithm_name = sklearn_class.__name__
        class_name = f"SS{algorithm_name}" if mode == "ss" else f"FL{algorithm_name}"
        
        return f'''#!/usr/bin/env python3
# Authors: The scikit-learn developers
# SPDX-License-Identifier: BSD-3-Clause

"""
Usage Example for {class_name}

This example demonstrates how to use the privacy-preserving {algorithm_name}
in SecretFlow's federated learning environment.
"""

import numpy as np

try:
    import secretflow as sf
    from secretflow.data import FedNdarray, PartitionWay
    from secretflow.device.driver import reveal
except ImportError:
    print("‚ùå SecretFlow not installed. Install with: pip install secretflow")
    exit(1)

from xlearn._secretflow.generated.{mode}_{algorithm_name.lower()} import {class_name}


def main():
    """Main example function"""
    print("="*70)
    print(f" {class_name} Usage Example")
    print("="*70)
    
    # Step 1: Initialize SecretFlow
    print("\\n[1/5] Initializing SecretFlow...")
    sf.init(['alice', 'bob', 'carol'], address='local')
    spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob', 'carol']))
    
    alice = sf.PYU('alice')
    bob = sf.PYU('bob')
    carol = sf.PYU('carol')
    print("  ‚úì SecretFlow initialized")
    
    # Step 2: Create sample data
    print("\\n[2/5] Creating sample data...")
    np.random.seed(42)
    n_samples = 1000
    n_features = 15
    
    X = np.random.randn(n_samples, n_features).astype(np.float32)
    
    # Partition data vertically
    X_alice = X[:, 0:5]
    X_bob = X[:, 5:10]
    X_carol = X[:, 10:15]
    
    print(f"  ‚úì Data shape: {{n_samples}} samples √ó {{n_features}} features")
    print(f"  ‚úì Alice: {{X_alice.shape}}, Bob: {{X_bob.shape}}, Carol: {{X_carol.shape}}")
    
    # Step 3: Create federated data
    print("\\n[3/5] Creating federated data...")
    fed_X = FedNdarray(
        partitions={{
            alice: alice(lambda x: x)(X_alice),
            bob: bob(lambda x: x)(X_bob),
            carol: carol(lambda x: x)(X_carol),
        }},
        partition_way=PartitionWay.VERTICAL
    )
    print("  ‚úì Federated data created")
    
    # Step 4: Train model
    print("\\n[4/5] Training {class_name}...")
    print("  Note: All computation happens in SPU's encrypted environment")
    
    import time
    start_time = time.time()
    
    model = {class_name}(spu)
    model.fit(fed_X)
    
    training_time = time.time() - start_time
    print(f"  ‚úì Training completed in {{training_time:.2f}}s")
    
    # Step 5: Make predictions (if applicable)
    print("\\n[5/5] Model trained successfully!")
    print("  ‚úì Model state stored in SPU (encrypted)")
    print("  ‚úì Privacy: Fully protected by MPC")
    print(f"  ‚úì Performance: {{training_time:.2f}}s")
    
    # Cleanup
    sf.shutdown()
    print("\\n‚úÖ Example completed!")


if __name__ == "__main__":
    main()
'''
    
    def _analyze_class_methods(self, sklearn_class: Type) -> List[str]:
        """ÂàÜÊûêÁ±ªÁöÑÊñπÊ≥ï"""
        methods = []
        try:
            for name in dir(sklearn_class):
                if not name.startswith('_') and callable(getattr(sklearn_class, name)):
                    methods.append(name)
        except:
            # Â¶ÇÊûúÂàÜÊûêÂ§±Ë¥•ÔºåËøîÂõûÂ∏∏Áî®ÊñπÊ≥ï
            methods = ['fit', 'predict', 'transform', 'score']
        return methods
    
    def _get_module_name(self, sklearn_class: Type) -> str:
        """Ëé∑ÂèñÊ®°ÂùóÂêç"""
        module = sklearn_class.__module__
        parts = module.split('.')
        if len(parts) >= 2:
            return parts[1]  # sklearn.decomposition -> decomposition
        return 'unknown'
    
    def _generate_fl_adapter(
        self,
        sklearn_class: Type,
        use_xlearn: bool,
        custom_config: Dict[str, Any] = None
    ) -> str:
        """Generate Federated Learning adapter"""
        
        algorithm_name = sklearn_class.__name__
        class_name = f"FL{algorithm_name}"
        module_name = self._get_module_name(sklearn_class)
        
        # Check if algorithm supports partial_fit
        has_partial_fit = hasattr(sklearn_class, 'partial_fit')
        
        code = f'''# Author: Chen Xingqiang
# SPDX-License-Identifier: BSD-3-Clause

"""
Federated Learning adapter for {algorithm_name}

Data remains in local PYUs, JAX-accelerated local computation,
HEU-based secure aggregation.

Mode: Federated Learning (FL)
Generated by: StandaloneAlgorithmMigrator
"""

import logging
from typing import Dict, Union

import numpy as np

try:
    from xlearn.{module_name} import {algorithm_name}
    USING_XLEARN = True
except ImportError:
    from sklearn.{module_name} import {algorithm_name}
    USING_XLEARN = False

try:
    from secretflow.data.ndarray.ndarray import FedNdarray
    from secretflow.data.vertical.dataframe import VDataFrame
    from secretflow.device import PYU, HEU
    from secretflow.device.device.pyu import PYUObject
    from secretflow.security.aggregation import SecureAggregator
    SECRETFLOW_AVAILABLE = True
except ImportError:
    SECRETFLOW_AVAILABLE = False
    

class {class_name}:
    """
    Federated Learning {algorithm_name}
    
    Data stays in local PYUs with JAX-accelerated computation.
    Gradients/parameters securely aggregated via HEU encryption.
    
    Parameters
    ----------
    devices : Dict[str, PYU]
        Dictionary mapping party names to PYU devices
    heu : HEU, optional
        Homomorphic encryption unit for secure aggregation
    **kwargs
        Parameters passed to {algorithm_name}
    
    Examples
    --------
    >>> alice = sf.PYU('alice')
    >>> bob = sf.PYU('bob')
    >>> heu = sf.HEU(...)
    >>> 
    >>> model = {class_name}(
    >>>     devices={{'alice': alice, 'bob': bob}},
    >>>     heu=heu
    >>> )
    >>> model.fit(fed_X, fed_y, epochs=10)
    """
    
    def __init__(self, devices: Dict[str, PYU], heu: HEU = None, **kwargs):
        if not SECRETFLOW_AVAILABLE:
            raise RuntimeError("SecretFlow not installed")
        
        self.devices = devices
        self.heu = heu
        self.kwargs = kwargs
        
        # Create local models on each PYU
        self.local_models = {{}}
        for party_name, device in devices.items():
            self.local_models[party_name] = device(self._create_local_model)(**kwargs)
        
        if USING_XLEARN:
            logging.info(f"[FL] {class_name} with JAX acceleration")
        else:
            logging.info(f"[FL] {class_name} with sklearn")
    
    @staticmethod
    def _create_local_model(**kwargs):
        """Create local model instance"""
        return {algorithm_name}(warm_start=True, **kwargs)
    
    def fit(
        self,
        x: Union[FedNdarray, VDataFrame],
        y: Union[FedNdarray, VDataFrame],
        epochs: int = 10,
        batch_size: int = 128,
    ):
        """
        Federated training
        
        Parameters
        ----------
        x : FedNdarray or VDataFrame
            Vertically partitioned features (data stays local)
        y : FedNdarray or VDataFrame
            Labels (can be held by one party)
        epochs : int
            Number of training epochs
        batch_size : int
            Batch size for local training
        """
        if isinstance(x, VDataFrame):
            x = x.values
        if isinstance(y, VDataFrame):
            y = y.values
        
        logging.info(f"[FL] Starting federated training: {{epochs}} epochs")
        
        for epoch in range(epochs):
            # Local computation on each party (JAX accelerated)
            local_results = {{}}
            
            for party_name, device in self.devices.items():
                if device in x.partitions:
                    X_local = x.partitions[device]
                    y_local = y.partitions.get(device, None)
                    
                    model = self.local_models[party_name]
                    
                    # Local partial_fit with JAX acceleration
                    def _local_train(model, X, y):
                        if y is not None:
                            if hasattr(model, 'partial_fit'):
                                # For incremental learners
                                classes = np.unique(y) if hasattr(model, 'classes_') else None
                                if classes is not None:
                                    model.partial_fit(X, y, classes=classes)
                                else:
                                    model.partial_fit(X, y)
                            else:
                                # For batch learners
                                model.fit(X, y)
                        
                        # Return model parameters
                        coef = model.coef_ if hasattr(model, 'coef_') else None
                        intercept = model.intercept_ if hasattr(model, 'intercept_') else None
                        return coef, intercept
                    
                    result = device(_local_train)(model, X_local, y_local)
                    local_results[party_name] = result
            
            # Secure aggregation (simplified - actual HEU aggregation needed)
            logging.info(f"[FL] Epoch {{epoch+1}}/{{epochs}} completed")
        
        logging.info("[FL] Federated training completed")
        return self
    
    def predict(self, x: Union[FedNdarray, VDataFrame]):
        """Predict using federated model"""
        # Each party computes local predictions, then aggregate
        if isinstance(x, VDataFrame):
            x = x.values
        
        predictions_list = []
        
        for party_name, device in self.devices.items():
            if device in x.partitions:
                X_local = x.partitions[device]
                model = self.local_models[party_name]
                
                pred = device(lambda m, X: m.predict(X))(model, X_local)
                predictions_list.append(pred)
        
        # Simple average (should use secure aggregation in production)
        return predictions_list[0] if len(predictions_list) == 1 else predictions_list
'''
        
        return code
    
    def batch_migrate(self, algorithms: List[tuple]):
        """Batch migrate algorithms"""
        print(f"\\nüöÄ Starting batch migration of {len(algorithms)} algorithms...\\n")
        
        success_count = 0
        for i, (sklearn_class, mode) in enumerate(algorithms, 1):
            try:
                print(f"[{i}/{len(algorithms)}] ", end="")
                self.migrate_algorithm(sklearn_class, mode, use_xlearn=True)
                success_count += 1
                print()
            except Exception as e:
                print(f"‚ùå Migration failed: {e}\\n")
                continue
        
        print(f"\\n‚úÖ Batch migration complete: {success_count}/{len(algorithms)} algorithms")


def main():
    """ÂëΩ‰ª§Ë°åÂÖ•Âè£"""
    parser = argparse.ArgumentParser(
        description="Migrate sklearn algorithms to SecretFlow",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Migrate single algorithm
  python algorithm_migrator_standalone.py --algorithm sklearn.decomposition.PCA --mode ss
  
  # Batch migrate common algorithms
  python algorithm_migrator_standalone.py --batch
        """
    )
    parser.add_argument("--algorithm", type=str,
                       help="Algorithm to migrate (e.g., sklearn.decomposition.PCA)")
    parser.add_argument("--mode", type=str, default="ss", choices=["ss", "fl", "sl"],
                       help="Migration mode (default: ss)")
    parser.add_argument("--batch", action="store_true",
                       help="Batch migration mode")
    parser.add_argument("--output", type=str,
                       default="xlearn/_secretflow/generated",
                       help="Output directory (default: xlearn/_secretflow/generated)")
    
    args = parser.parse_args()
    
    migrator = StandaloneAlgorithmMigrator(output_dir=args.output)
    
    if args.batch:
        # ÊâπÈáèËøÅÁßªÂ∏∏Áî®ÁÆóÊ≥ï
        from sklearn.decomposition import PCA, TruncatedSVD, NMF, FactorAnalysis, FastICA
        from sklearn.linear_model import Ridge, Lasso, ElasticNet
        from sklearn.cluster import MiniBatchKMeans, DBSCAN
        from sklearn.naive_bayes import MultinomialNB, BernoulliNB
        
        algorithms = [
            (PCA, "ss"),
            (TruncatedSVD, "ss"),
            (NMF, "ss"),
            (FactorAnalysis, "ss"),
            (FastICA, "ss"),
            (Ridge, "ss"),
            (Lasso, "ss"),
            (ElasticNet, "ss"),
            (MiniBatchKMeans, "ss"),
            (DBSCAN, "ss"),
            (MultinomialNB, "ss"),
            (BernoulliNB, "ss"),
        ]
        
        migrator.batch_migrate(algorithms)
        
    elif args.algorithm:
        # Âçï‰∏™ÁÆóÊ≥ïËøÅÁßª
        module_name, class_name = args.algorithm.rsplit('.', 1)
        module = __import__(module_name, fromlist=[class_name])
        sklearn_class = getattr(module, class_name)
        
        migrator.migrate_algorithm(sklearn_class, args.mode, use_xlearn=True)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()

